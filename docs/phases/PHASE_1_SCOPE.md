# Phase 1 - E-Mail Intake + Analyse + Tagesjournal

**MVP fÃ¼r Digital Twin Plattform**

---

## ğŸ¯ Phase-1-Ziel

**Ein funktionierendes E-Mail-Verarbeitungssystem, das:**
- E-Mails einliest
- Intelligent analysiert und klassifiziert
- Tasks, Decisions und Questions extrahiert
- Ein tÃ¤gliches Journal generiert
- Feedback-Loops implementiert (HITL)

**Scope:** Nur E-Mails als Input-Kanal
**Dauer:** 2-3 Monate
**Status:** In Entwicklung (Week 1-2 abgeschlossen)

---

## âœ… Was bereits existiert (Week 1-2)

### 1. Input Hub (E-Mail)
**Status:** âœ… VollstÃ¤ndig implementiert

**Implementierte Features:**
- Gmail API Integration (OAuth2)
- IMAP/SMTP Support (Ionos)
- Multi-Account Support (3x Gmail + 1x Ionos)
- Email-Fetching (unread emails)
- Token-Management (auto-refresh)

**Code:**
- `modules/email/tools/gmail_tools.py` (Gmail API)
- `modules/email/tools/ionos_tools.py` (IMAP/SMTP)

---

### 2. Analysis Engine (Classification)
**Status:** âœ… VollstÃ¤ndig implementiert

**3-Layer Classification Pipeline:**
```
Email Input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Layer 1: RULE LAYER               â”‚
â”‚   â€¢ Spam patterns (â‰¥95% confidence) â”‚
â”‚   â€¢ Newsletter patterns (â‰¥85%)      â”‚
â”‚   â€¢ Auto-reply detection (â‰¥90%)     â”‚
â”‚   â€¢ Fast: <1ms per email            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ confidence < 0.85
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Layer 2: HISTORY LAYER            â”‚
â”‚   â€¢ Sender preferences (EMA)        â”‚
â”‚   â€¢ Domain preferences              â”‚
â”‚   â€¢ Fast: <10ms per email           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ confidence < 0.85
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Layer 3: LLM LAYER                â”‚
â”‚   â€¢ Ollama (gptoss20b) - Primary    â”‚
â”‚   â€¢ OpenAI (gpt-4o) - Fallback      â”‚
â”‚   â€¢ Slow: ~1-3s per email           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Early Stopping:** 60-80% der Emails werden von Rule/History Layers klassifiziert!

**Implementierte Kategorien:**
- `wichtig` - Wichtige persÃ¶nliche/geschÃ¤ftliche Nachrichten
- `action_required` - Dringende Aktionen erforderlich
- `nice_to_know` - Informativ, keine sofortige Aktion
- `newsletter` - Newsletter, Marketing
- `system_notifications` - Automatische System-Benachrichtigungen
- `spam` - UnerwÃ¼nschte Emails

**Code:**
- `agent_platform/classification/importance_rules.py` (Rule Layer)
- `agent_platform/classification/importance_history.py` (History Layer)
- `agent_platform/classification/importance_llm.py` (LLM Layer)
- `agent_platform/classification/unified_classifier.py` (Orchestration)
- `agent_platform/classification/agents/` (OpenAI Agents SDK wrappers)

---

### 3. Memory System (Partial)
**Status:** âœ… Teilweise implementiert

**Existierende Memory-Objects:**

#### ProcessedEmail
```python
class ProcessedEmail(Base):
    email_id: str
    account_id: str
    category: str
    importance: float
    confidence: float
    layer_used: str
    processed_at: datetime
```

#### SenderPreference (EMA Learning)
```python
class SenderPreference(Base):
    account_id: str
    sender_email: str
    sender_domain: str
    total_emails_received: int
    reply_rate: float  # EMA Î±=0.15
    archive_rate: float
    delete_rate: float
    avg_time_to_reply_hours: float
```

#### DomainPreference
```python
class DomainPreference(Base):
    account_id: str
    domain: str
    total_emails_received: int
    reply_rate: float  # EMA Î±=0.15
    archive_rate: float
```

**Code:**
- `agent_platform/db/models.py` (Database Models)
- `agent_platform/db/database.py` (Session Management)
- `agent_platform/feedback/tracker.py` (EMA Learning)

---

### 4. Review & Feedback System
**Status:** âœ… VollstÃ¤ndig implementiert

**Implementierte Features:**
- Review Queue (medium-confidence emails)
- Daily Digest (HTML Email mit Action Buttons)
- Feedback Tracking (reply/archive/delete/star)
- EMA Learning (Î±=0.15) aus User-Aktionen

**Code:**
- `agent_platform/review/queue_manager.py`
- `agent_platform/review/digest_generator.py`
- `agent_platform/review/review_handler.py`
- `agent_platform/feedback/tracker.py`
- `agent_platform/feedback/checker.py`

---

### 5. Orchestration & Scheduling
**Status:** âœ… VollstÃ¤ndig implementiert

**Scheduled Jobs:**
- Daily Digest: 9 AM
- Feedback Check: Every hour
- Queue Cleanup: 2 AM

**Code:**
- `agent_platform/orchestration/classification_orchestrator.py`
- `agent_platform/orchestration/scheduler_jobs.py`
- `scripts/operations/run_scheduler.py`

---

### 6. Tests & Monitoring
**Status:** âœ… VollstÃ¤ndig implementiert

**Test Coverage:**
- 23/23 Tests passing (100%)
- E2E Tests mit real Gmail
- Agent Migration Tests (OpenAI Agents SDK)

**Code:**
- `tests/classification/` (4 tests)
- `tests/integration/` (2 E2E tests)
- `tests/feedback/` (6 tests)
- `tests/review/` (7 tests)
- `tests/agents/` (2 migration tests)

---

## ğŸ”„ Was noch fehlt fÃ¼r Phase 1 MVP

### 1. Event-Log System
**Status:** âŒ Nicht implementiert

**Ziel:**
- Alle Aktionen als unverÃ¤nderliche Events speichern
- Event-Types:
  - `EMAIL_RECEIVED`
  - `EMAIL_ANALYZED`
  - `EMAIL_CLASSIFIED`
  - `TASK_EXTRACTED`
  - `DECISION_EXTRACTED`
  - `QUESTION_EXTRACTED`
  - `USER_FEEDBACK` (reply/archive/delete)
  - `JOURNAL_GENERATED`

**Implementierung:**
```python
class Event(Base):
    event_id: str (UUID)
    event_type: str
    timestamp: datetime
    account_id: str
    email_id: Optional[str]
    payload: JSON
    metadata: JSON
```

**PrioritÃ¤t:** ğŸ”¥ Hoch (Grundlage fÃ¼r alles Weitere)

---

### 2. Erweiterte E-Mail-Analyse
**Status:** âŒ Nicht implementiert

**Ziel:**
- Ãœber Klassifikation hinausgehen
- Semantic Analysis fÃ¼r Extraktion

**Neue Analyse-Funktionen:**

#### Zusammenfassung
```python
class EmailSummary(BaseModel):
    summary: str  # 2-3 SÃ¤tze Zusammenfassung
    key_points: list[str]  # 3-5 wichtigste Punkte
    sentiment: str  # positive/neutral/negative
```

#### Task-Extraktion
```python
class ExtractedTask(BaseModel):
    task_description: str
    priority: str  # high/medium/low
    deadline: Optional[str]
    context: str  # Kontext aus Email
```

#### Decision-Extraktion
```python
class ExtractedDecision(BaseModel):
    decision_question: str
    options: list[str]
    deadline: Optional[str]
    context: str
```

#### Question-Extraktion
```python
class ExtractedQuestion(BaseModel):
    question: str
    requires_answer: bool
    context: str
```

**Implementierung:**
- Neuer Agent: `ExtractionAgent` (OpenAI Agents SDK)
- LLM-basiert (Ollama-first + OpenAI fallback)
- Structured Outputs (Pydantic)

**PrioritÃ¤t:** ğŸ”¥ Hoch (Kernfunktion)

---

### 3. Memory-Objects erweitern
**Status:** âŒ Nicht implementiert

**Neue Memory-Objects:**

#### Task
```python
class Task(Base):
    task_id: str (UUID)
    source_email_id: str
    description: str
    priority: str
    deadline: Optional[datetime]
    status: str  # open/in_progress/completed/cancelled
    created_at: datetime
    updated_at: datetime
```

#### Decision
```python
class Decision(Base):
    decision_id: str (UUID)
    source_email_id: str
    question: str
    options: list[str] (JSON)
    deadline: Optional[datetime]
    status: str  # pending/decided/cancelled
    decision_made: Optional[str]
    decided_at: Optional[datetime]
```

#### Question
```python
class Question(Base):
    question_id: str (UUID)
    source_email_id: str
    question: str
    requires_answer: bool
    status: str  # open/answered/cancelled
    answer: Optional[str]
    answered_at: Optional[datetime]
```

#### JournalEntry
```python
class JournalEntry(Base):
    journal_id: str (UUID)
    date: date
    type: str  # daily/weekly
    content: str  # Markdown
    emails_processed: int
    tasks_extracted: int
    decisions_extracted: int
    questions_extracted: int
    generated_at: datetime
```

**Implementierung:**
- Database Models in `agent_platform/db/models.py`
- Abgeleitet aus Events
- KÃ¶nnen korrigiert werden (neue Events)

**PrioritÃ¤t:** ğŸ”¥ Hoch (benÃ¶tigt fÃ¼r Journal)

---

### 4. Tagesjournal-Generierung
**Status:** âŒ Nicht implementiert

**Ziel:**
- TÃ¤glich automatisch ein Journal generieren
- Zusammenfassung des Tages aus Events + Memory-Objects

**Journal-Struktur:**
```markdown
# Tagesjournal - 19. November 2025

## ğŸ“§ E-Mail-Verarbeitung

**Verarbeitet:** 47 Emails
**Wichtige Emails:** 8
**Action Required:** 5
**Newsletter:** 12
**Spam:** 3

## âœ… Extrahierte Aufgaben (12)

- [ ] Q4 Budget Review vorbereiten (Prio: High, Deadline: 22.11.)
- [ ] Meeting mit Team X planen (Prio: Medium)
- ...

## ğŸ¤” Offene Entscheidungen (3)

- Wahl zwischen Option A und B fÃ¼r Projekt Y (Deadline: 25.11.)
- ...

## â“ Offene Fragen (5)

- Frage von Kunde Z: "Wann ist das Feature fertig?"
- ...

## ğŸ“Š Statistiken

- Durchschnittliche Classification Zeit: 487ms
- Rule Layer Hit Rate: 65%
- LLM Layer Usage: 15%
```

**Implementierung:**
- Neuer Agent: `JournalGenerator` (OpenAI Agents SDK)
- Template-basiert (Markdown)
- Scheduled Job (tÃ¤glich 20:00 Uhr)
- Export als `.md` File

**PrioritÃ¤t:** ğŸ”¶ Medium (nach Extraktion)

---

### 5. HITL Feedback-Interface
**Status:** ğŸ”¶ Teilweise implementiert

**Was existiert:**
- âœ… Daily Digest mit Action Buttons
- âœ… Feedback Tracking (reply/archive/delete)
- âœ… EMA Learning aus Feedback

**Was fehlt:**
- âŒ Korrektur-Interface fÃ¼r Klassifikationen
- âŒ Korrektur-Interface fÃ¼r Tasks/Decisions/Questions
- âŒ BestÃ¤tigungs-Interface
- âŒ Feedback-Events in Event-Log

**Neue Implementierung:**
- Web-UI (Flask/FastAPI) fÃ¼r Korrekturen
- API Endpoints:
  - `POST /feedback/classification` (Korrektur)
  - `POST /feedback/task` (Korrektur)
  - `POST /feedback/confirm` (BestÃ¤tigung)
- Feedback erzeugt Events
- Events flieÃŸen zurÃ¼ck in Learning-Loop

**PrioritÃ¤t:** ğŸ”¶ Medium (nach Extraktion)

---

## ğŸ¯ NÃ¤chste Schritte (Priorisiert)

### Schritt 1: Event-Log System â­
**Warum zuerst?**
- Grundlage fÃ¼r alle weiteren Features
- Event-First Architecture ist Kernprinzip
- Nachvollziehbarkeit aller Aktionen

**Tasks:**
1. Database Model fÃ¼r `Event` erstellen
2. Event-Service implementieren (`agent_platform/events/event_service.py`)
3. Bestehende Aktionen mit Events instrumentieren:
   - EMAIL_RECEIVED (bei Email-Fetch)
   - EMAIL_CLASSIFIED (nach Classification)
   - USER_FEEDBACK (bei Feedback-Tracking)
4. Tests fÃ¼r Event-System
5. Migration fÃ¼r Event-Tabelle

**Dauer:** 1-2 Tage

---

### Schritt 2: Erweiterte E-Mail-Analyse (Extraktion) â­â­
**Warum als zweites?**
- Kernfunktion fÃ¼r Phase 1
- BenÃ¶tigt Event-System (Events fÃ¼r Extraktion)

**Tasks:**
1. `ExtractionAgent` implementieren (OpenAI Agents SDK)
2. Pydantic Models fÃ¼r Structured Outputs:
   - `EmailSummary`
   - `ExtractedTask`
   - `ExtractedDecision`
   - `ExtractedQuestion`
3. LLM Prompts fÃ¼r Extraktion
4. Integration in Classification Pipeline
5. Events erzeugen:
   - TASK_EXTRACTED
   - DECISION_EXTRACTED
   - QUESTION_EXTRACTED
6. Tests fÃ¼r Extraktion

**Dauer:** 2-3 Tage

---

### Schritt 3: Memory-Objects (Tasks, Decisions, Questions) â­â­
**Warum als drittes?**
- BenÃ¶tigt Event-System + Extraktion
- Grundlage fÃ¼r Journal

**Tasks:**
1. Database Models erstellen:
   - `Task`
   - `Decision`
   - `Question`
2. Service-Layer fÃ¼r Memory-Objects:
   - `agent_platform/memory/task_service.py`
   - `agent_platform/memory/decision_service.py`
   - `agent_platform/memory/question_service.py`
3. Memory-Objects aus Events ableiten
4. API Endpoints fÃ¼r CRUD
5. Tests fÃ¼r Memory-Objects
6. Migration fÃ¼r neue Tabellen

**Dauer:** 2-3 Tage

---

### Schritt 4: Tagesjournal-Generierung â­
**Warum als viertes?**
- BenÃ¶tigt alle vorherigen Schritte
- Showcase fÃ¼r Phase 1

**Tasks:**
1. `JournalGenerator` Agent implementieren
2. Markdown Template fÃ¼r Tagesjournal
3. Scheduled Job (tÃ¤glich 20:00 Uhr)
4. Export als `.md` File
5. Journal als `JournalEntry` in Database
6. Event: JOURNAL_GENERATED
7. Tests fÃ¼r Journal-Generierung

**Dauer:** 1-2 Tage

---

### Schritt 5: HITL Feedback-Interface â­
**Warum als letztes?**
- ErgÃ¤nzung zu bestehendem System
- Polishing fÃ¼r bessere UX

**Tasks:**
1. Web-UI (Flask/FastAPI) GrundgerÃ¼st
2. Korrektur-Interface fÃ¼r Klassifikationen
3. Korrektur-Interface fÃ¼r Tasks/Decisions/Questions
4. BestÃ¤tigungs-Interface
5. API Endpoints fÃ¼r Feedback
6. Feedback-Events erzeugen
7. Integration in Learning-Loop

**Dauer:** 3-4 Tage

---

## ğŸ“Š Phase 1 MVP - Definition of Done

Phase 1 ist **abgeschlossen**, wenn:

âœ… **Event-Log System:**
- [ ] Alle Aktionen werden als Events gespeichert
- [ ] Events sind unverÃ¤nderlich (Append-Only)
- [ ] Event-Historie ist vollstÃ¤ndig nachvollziehbar

âœ… **E-Mail-Analyse:**
- [ ] Klassifikation funktioniert (bereits âœ…)
- [ ] Zusammenfassung wird generiert
- [ ] Tasks werden extrahiert
- [ ] Decisions werden extrahiert
- [ ] Questions werden extrahiert

âœ… **Memory-Objects:**
- [ ] Tasks werden in Database gespeichert
- [ ] Decisions werden in Database gespeichert
- [ ] Questions werden in Database gespeichert
- [ ] Memory-Objects kÃ¶nnen korrigiert werden

âœ… **Tagesjournal:**
- [ ] Journal wird tÃ¤glich generiert
- [ ] Journal enthÃ¤lt Zusammenfassung + Tasks + Decisions + Questions
- [ ] Journal wird als Markdown exportiert

âœ… **HITL Feedback:**
- [ ] Feedback-Interface existiert
- [ ] Korrekturen erzeugen Events
- [ ] Feedback flieÃŸt zurÃ¼ck in Learning-Loop

âœ… **Tests & Monitoring:**
- [ ] Alle neuen Features haben Tests
- [ ] E2E-Tests fÃ¼r kompletten Workflow
- [ ] System lÃ¤uft stabil im Produktionsbetrieb

---

## ğŸš« Explizit NICHT Teil von Phase 1

âŒ Twin Core (PersÃ¶nlichkeit, PrÃ¤ferenz-Modell)
âŒ Chat-Interface (natÃ¼rliche Konversation)
âŒ Knowledge Graph (Visualisierung)
âŒ Musteranalyse (Ã¼ber Zeit)
âŒ Personen-Analyse (Beziehungen)
âŒ Themen-Erkennung (Topics)
âŒ Weitere Input-KanÃ¤le (Kalender, Notizen, etc.)
âŒ Proaktive Automationen
âŒ Wochenjournal (kommt Phase 2)

---

## ğŸ“… Zeitplan (geschÃ¤tzt)

**Week 1-2:** âœ… Email Classification System (abgeschlossen)
**Week 3:** Event-Log System
**Week 4:** Erweiterte E-Mail-Analyse (Extraktion)
**Week 5:** Memory-Objects (Tasks, Decisions, Questions)
**Week 6:** Tagesjournal-Generierung
**Week 7:** HITL Feedback-Interface
**Week 8:** Testing, Polishing, Documentation

**Gesamt:** ~8 Wochen (2 Monate)

---

## ğŸ¯ Erfolgs-Metriken fÃ¼r Phase 1

- [ ] 90%+ der E-Mails werden korrekt klassifiziert âœ… (bereits erfÃ¼llt)
- [ ] Tasks werden mit 80%+ Genauigkeit extrahiert
- [ ] Decisions werden mit 70%+ Genauigkeit extrahiert
- [ ] Questions werden mit 85%+ Genauigkeit extrahiert
- [ ] Tagesjournal wird tÃ¤glich generiert (100% Uptime)
- [ ] HITL-Feedback wird in 100% der FÃ¤lle erfasst
- [ ] System lÃ¤uft stabil (>99% Uptime)

---

**Status:** Week 1-2 abgeschlossen, Week 3 beginnt mit Event-Log System! ğŸš€
